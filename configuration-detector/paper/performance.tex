We measured \ourtool's performance in two ways: the time cost
in diagnosing an error and the overhead introduced
in reproducing an error in a \ourtool-instrumented program.  Figure~\ref{tab:performance}
shows the results.

\begin{figure}[t]
\setlength{\tabcolsep}{.94\tabcolsep}
\small{
\begin{tabular}{|l|c|c|c|}
\hline
 Error ID. & \multicolumn{2}{|c|}{Time (seconds)} & Slowdown ($\times$)\\
  %& \multicolumn{3}{|c|}{Different Comparison Profile Selection Strategy} \\
\cline{2-3}
 Program & Thin Slicing & Error Diagnosis &  \\
 \hline
\hline
\multicolumn{4}{|l|}{Non-crashing errors}   \\
 \hline
 1. Randoop & 50 & $<$ 1 & 1.1\\
 2. Weka & 43 & $<$ 1 & 1.2 \\
 3. JChord & 147 & 82 & 13.2\\
 4. Synoptic & 24 & $<$ 1 & 3.6 \\
 5. Soot & 95 & 21 & 3.1 \\
\hline
Average & 72 & 21 & 4.4\\
\hline
\hline
\multicolumn{4}{|l|}{Crashing errors}   \\
\hline
 6. JChord & 147 & 79 & 2.4\\
 7. JChord & 147 & 75 & 1.4\\
 8. JChord & 147 & 17 &1.5\\
 9. JChord & 147 & 30 & 28.5\\
 10. JChord & 147 & 13 &13.7\\
 11. JChord & 147 & 10 &65.1 \\
 12. JChord & 147 & 83 &1.6\\
 13. JChord & 147 & 8 &1.9\\
 14. JChord & 147 & 80 &1.4\\
\hline
Average & 147 & 44 & 13\\
\hline
\end{tabular}
}
\Caption{{\label{tab:performance} \ourtool's
performance in diagnosing configuration
errors. The time cost has been divided into
two parts: computing thin slices and diagnosing
an error.}}
\end{figure}

The performance of \ourtool is reasonable.
On average, it uses \avgtime minutes to
diagnose one configuration error. Computing
thin slices for all configuration options
is expensive. However, this step is one-time effort
per program and the computed slices can be cached
to share across diagnoses. %for future use.

The performance overhead to reproduce the buggy behavior varies
among applications. The current tool implementation
imposes an average slowdown of 13 times when reproducing
an error in a \ourtool-instrumented version.
This performance overhead, admittedly high, is still acceptable
for offline error diagnosis.
For errors 3, 9, 10, and 11, the slowdown is signficiant, but the
absolute time cost for error reproduction is still low ( $<$ 13 minutes per error).  
For the other 10 errors, the average slowdown is only 1.9.

%\todo{Maybe add one more sentence here: for error 9, 10, 11, the slowdown for
%reproducing a crashing error is very large. However, the absolute
%time cost is very low, on the original JChord version, all these three errors exhibit in less than 5 seconds. Thus, even with a 65X slowdown, the absolute time cost
%is still acceptable (around 5 mins).}

%The size of profile files in the database $\blacksquare$


%The performance of \ourtool is reasonable. The time to diagnose
%an error varies among applications.  XXX app takes less than xxx,
%while xxx takes xxx to complete.

